# CPSC_8430--Deep_Learning_HW1
Deep Learning Homework1 Submission

Implementation files
Cifar Training files: Cifar/pytorch_training2.py 

Cifar DataLoader and Transform file:- Cifar/cifar_dl_dt_helper.py

Helper functions for grad_norm, sensitivity analysis - Cifar/pytorch_model_helper.py 


# HW 1_1 (Main Files)
Simulated Function 1 : Section1/HW1_1SimulatedFunc1_final/SimFunc1_Main.py

Simulated Function 2 : Section1/HW1_1SimulatedFunc1_final/SimFunc2_Main.py

Cifar10 3 Model : Cifar/Cifar3Models_hw_1_3.ipynb

# HW 1_2 (Main Files):

Visualization of weights with different epochs for multiple times:- Cifar/cifar 10_wts _16_feb_Final-Copy1.ipynb

Observation for Gradient Norm- Section1/HW1_1SimulatedFunc1_final/Hw1_simulated_function1_withgrad_norm_final.ipynb

Minimal Ratio vs loss plotting using hessian matrix :- Mnist/Hessian_new.ipynb

Random Shuffling of MNIST training data and Testing it for original Test Data :- Mnist/RandomMinist_Shuffle.py

# HW 1_3 (Main Files)

10 Cifar models for Number of parameters with generalization:- Cifar/Cifar10Models_final_notebook_3_1.ipynb

Influence of Accuracy loss and sensitivity with increasing Batch Size :- 
Cifar/Batch_sizes_models_hw_3_2_3_3.ipynb

Influence of  Accuracy loss and sensitivity with increasing Learning rate :- Cifar/lr_alpha_hw_3_2_3_3.ipynb

